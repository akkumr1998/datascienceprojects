{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "174cfbc4",
   "metadata": {},
   "source": [
    "# ANN Regression Model \n",
    "\n",
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bbfac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f071baa",
   "metadata": {},
   "source": [
    "# Part-1 Data Processing\n",
    "\n",
    "Import Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1189f5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>16.65</td>\n",
       "      <td>49.69</td>\n",
       "      <td>1014.01</td>\n",
       "      <td>91.00</td>\n",
       "      <td>460.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>13.19</td>\n",
       "      <td>39.18</td>\n",
       "      <td>1023.67</td>\n",
       "      <td>66.78</td>\n",
       "      <td>469.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>31.32</td>\n",
       "      <td>74.33</td>\n",
       "      <td>1012.92</td>\n",
       "      <td>36.48</td>\n",
       "      <td>429.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>24.48</td>\n",
       "      <td>69.45</td>\n",
       "      <td>1013.86</td>\n",
       "      <td>62.39</td>\n",
       "      <td>435.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>21.60</td>\n",
       "      <td>62.52</td>\n",
       "      <td>1017.23</td>\n",
       "      <td>67.87</td>\n",
       "      <td>453.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9568 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AT      V       AP     RH      PE\n",
       "0     14.96  41.76  1024.07  73.17  463.26\n",
       "1     25.18  62.96  1020.04  59.08  444.37\n",
       "2      5.11  39.40  1012.16  92.14  488.56\n",
       "3     20.86  57.32  1010.24  76.64  446.48\n",
       "4     10.82  37.50  1009.23  96.62  473.90\n",
       "...     ...    ...      ...    ...     ...\n",
       "9563  16.65  49.69  1014.01  91.00  460.03\n",
       "9564  13.19  39.18  1023.67  66.78  469.62\n",
       "9565  31.32  74.33  1012.92  36.48  429.57\n",
       "9566  24.48  69.45  1013.86  62.39  435.74\n",
       "9567  21.60  62.52  1017.23  67.87  453.28\n",
       "\n",
       "[9568 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('Folds5x2_pp.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcdbb08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9568 entries, 0 to 9567\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      9568 non-null   float64\n",
      " 1   V       9568 non-null   float64\n",
      " 2   AP      9568 non-null   float64\n",
      " 3   RH      9568 non-null   float64\n",
      " 4   PE      9568 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 373.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a74961a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26.27</td>\n",
       "      <td>59.44</td>\n",
       "      <td>1012.23</td>\n",
       "      <td>58.77</td>\n",
       "      <td>443.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.89</td>\n",
       "      <td>43.96</td>\n",
       "      <td>1014.02</td>\n",
       "      <td>75.24</td>\n",
       "      <td>467.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.48</td>\n",
       "      <td>44.71</td>\n",
       "      <td>1019.12</td>\n",
       "      <td>66.43</td>\n",
       "      <td>478.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.64</td>\n",
       "      <td>45.00</td>\n",
       "      <td>1021.78</td>\n",
       "      <td>41.25</td>\n",
       "      <td>475.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.74</td>\n",
       "      <td>43.56</td>\n",
       "      <td>1015.14</td>\n",
       "      <td>70.72</td>\n",
       "      <td>477.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH      PE\n",
       "0  14.96  41.76  1024.07  73.17  463.26\n",
       "1  25.18  62.96  1020.04  59.08  444.37\n",
       "2   5.11  39.40  1012.16  92.14  488.56\n",
       "3  20.86  57.32  1010.24  76.64  446.48\n",
       "4  10.82  37.50  1009.23  96.62  473.90\n",
       "5  26.27  59.44  1012.23  58.77  443.67\n",
       "6  15.89  43.96  1014.02  75.24  467.35\n",
       "7   9.48  44.71  1019.12  66.43  478.42\n",
       "8  14.64  45.00  1021.78  41.25  475.98\n",
       "9  11.74  43.56  1015.14  70.72  477.50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77475f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = ['PE']\n",
    "predictors = ['AT', 'V', 'AP', 'RH']\n",
    "x=data[predictors].values\n",
    "y=data[target_variable].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73efdbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14.96,   41.76, 1024.07,   73.17],\n",
       "       [  25.18,   62.96, 1020.04,   59.08],\n",
       "       [   5.11,   39.4 , 1012.16,   92.14],\n",
       "       ...,\n",
       "       [  31.32,   74.33, 1012.92,   36.48],\n",
       "       [  24.48,   69.45, 1013.86,   62.39],\n",
       "       [  21.6 ,   62.52, 1017.23,   67.87]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59a804f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[463.26],\n",
       "       [444.37],\n",
       "       [488.56],\n",
       "       ...,\n",
       "       [429.57],\n",
       "       [435.74],\n",
       "       [453.28]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e293384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7654, 4)\n",
      "(7654, 1)\n",
      "(1914, 4)\n",
      "(1914, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Quick sanity check with the shapes of Training and testing datasets\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d62f46",
   "metadata": {},
   "source": [
    "# Part - 2 : Building the ANN\n",
    "\n",
    "Intializing ANN\n",
    "\n",
    "Lets quickly understand the hyperparameters in below code snippets\n",
    "\n",
    "* units=6: This means we are creating a layer with five neurons in it. Each of these six neurons will be receiving the values of inputs, for example, the values of â€˜ATâ€™ will be passed to all six neurons, similarly all other columns.\n",
    "\n",
    "* input_dim=4: This means there are seven predictors in the input data which is expected by the first layer. If you see the second dense layer, we donâ€™t specify this value, because the Sequential model passes this information further to the next layers.\n",
    "\n",
    "* kernel_initializer=â€™normalâ€™: When the Neurons start their computation, some algorithm has to decide the value for each weight. This parameter specifies that. You can choose different values for it like â€˜normalâ€™ or â€˜glorot_uniformâ€™.\n",
    "\n",
    "* activation=â€™reluâ€™: This specifies the activation function for the calculations inside each neuron. You can choose values like â€˜reluâ€™, â€˜tanhâ€™, â€˜sigmoidâ€™, etc.\n",
    "\n",
    "* batch_size=32: This specifies how many rows will be passed to the Network in one go after which the SSE calculation will begin and the neural network will start adjusting its weights based on the errors. When all the rows are passed in the batches of 32 rows each as specified in this parameter, then we call that 1-epoch. Or one full data cycle. This is also known as mini-batch gradient descent. A small value of batch_size will make the ANN look at the data slowly, like 2 rows at a time or 4 rows at a time which could lead to overfitting, as compared to a large value like 20 or 50 rows at a time, which will make the ANN look at the data fast which could lead to underfitting. Hence a proper value must be chosen using hyperparameter tuning.\n",
    "\n",
    "* Epochs=100: The same activity of adjusting weights continues for 100 times, as specified by this parameter. In simple terms, the ANN looks at the full training data 100 times and adjusts its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be77e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b5eee0",
   "metadata": {},
   "source": [
    "Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdae5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6,input_dim=4, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbd67ea",
   "metadata": {},
   "source": [
    "Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65eaee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9915103",
   "metadata": {},
   "source": [
    "Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ce5ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d974727",
   "metadata": {},
   "source": [
    "# Part 3 - Training the ANN\n",
    "\n",
    "Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f56b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae39a90e",
   "metadata": {},
   "source": [
    "# Training the ANN model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "880535d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "240/240 [==============================] - 0s 546us/step - loss: 1707.0836 - val_loss: 509.8993\n",
      "Epoch 2/100\n",
      "240/240 [==============================] - 0s 680us/step - loss: 478.1786 - val_loss: 449.1300\n",
      "Epoch 3/100\n",
      "240/240 [==============================] - 0s 367us/step - loss: 394.7352 - val_loss: 339.3232\n",
      "Epoch 4/100\n",
      "240/240 [==============================] - 0s 369us/step - loss: 281.0145 - val_loss: 222.1513\n",
      "Epoch 5/100\n",
      "240/240 [==============================] - 0s 380us/step - loss: 160.4613 - val_loss: 108.7930\n",
      "Epoch 6/100\n",
      "240/240 [==============================] - 0s 374us/step - loss: 85.8889 - val_loss: 63.6952\n",
      "Epoch 7/100\n",
      "240/240 [==============================] - 0s 378us/step - loss: 56.0397 - val_loss: 46.8736\n",
      "Epoch 8/100\n",
      "240/240 [==============================] - 0s 372us/step - loss: 43.3611 - val_loss: 39.2518\n",
      "Epoch 9/100\n",
      "240/240 [==============================] - 0s 380us/step - loss: 37.8348 - val_loss: 33.9546\n",
      "Epoch 10/100\n",
      "240/240 [==============================] - 0s 383us/step - loss: 33.4868 - val_loss: 31.2248\n",
      "Epoch 11/100\n",
      "240/240 [==============================] - 0s 381us/step - loss: 30.9401 - val_loss: 28.6048\n",
      "Epoch 12/100\n",
      "240/240 [==============================] - 0s 375us/step - loss: 29.1754 - val_loss: 26.9364\n",
      "Epoch 13/100\n",
      "240/240 [==============================] - 0s 377us/step - loss: 28.3605 - val_loss: 26.1445\n",
      "Epoch 14/100\n",
      "240/240 [==============================] - 0s 370us/step - loss: 27.7103 - val_loss: 25.1733\n",
      "Epoch 15/100\n",
      "240/240 [==============================] - 0s 366us/step - loss: 27.5331 - val_loss: 25.0325\n",
      "Epoch 16/100\n",
      "240/240 [==============================] - 0s 368us/step - loss: 26.4863 - val_loss: 25.4526\n",
      "Epoch 17/100\n",
      "240/240 [==============================] - 0s 376us/step - loss: 27.0437 - val_loss: 28.2280\n",
      "Epoch 18/100\n",
      "240/240 [==============================] - 0s 375us/step - loss: 26.2998 - val_loss: 25.7892\n",
      "Epoch 19/100\n",
      "240/240 [==============================] - 0s 375us/step - loss: 26.5271 - val_loss: 26.6776\n",
      "Epoch 20/100\n",
      "240/240 [==============================] - 0s 380us/step - loss: 25.9270 - val_loss: 23.3337\n",
      "Epoch 21/100\n",
      "240/240 [==============================] - 0s 378us/step - loss: 26.6359 - val_loss: 23.1628\n",
      "Epoch 22/100\n",
      "240/240 [==============================] - 0s 374us/step - loss: 26.6914 - val_loss: 23.0529\n",
      "Epoch 23/100\n",
      "240/240 [==============================] - 0s 377us/step - loss: 26.8552 - val_loss: 22.8893\n",
      "Epoch 24/100\n",
      "240/240 [==============================] - 0s 374us/step - loss: 25.6966 - val_loss: 23.2350\n",
      "Epoch 25/100\n",
      "240/240 [==============================] - 0s 377us/step - loss: 26.9887 - val_loss: 27.6241\n",
      "Epoch 26/100\n",
      "240/240 [==============================] - 0s 377us/step - loss: 26.2689 - val_loss: 23.9435\n",
      "Epoch 27/100\n",
      "240/240 [==============================] - 0s 381us/step - loss: 26.3562 - val_loss: 26.0196\n",
      "Epoch 28/100\n",
      "240/240 [==============================] - 0s 361us/step - loss: 25.9572 - val_loss: 22.6117\n",
      "Epoch 29/100\n",
      "240/240 [==============================] - 0s 365us/step - loss: 26.5069 - val_loss: 25.5117\n",
      "Epoch 30/100\n",
      "240/240 [==============================] - 0s 366us/step - loss: 25.8175 - val_loss: 24.7388\n",
      "Epoch 31/100\n",
      "240/240 [==============================] - 0s 369us/step - loss: 25.5924 - val_loss: 23.1953\n",
      "Epoch 32/100\n",
      "240/240 [==============================] - 0s 378us/step - loss: 26.8324 - val_loss: 24.3319\n",
      "Epoch 33/100\n",
      "240/240 [==============================] - 0s 407us/step - loss: 26.6434 - val_loss: 24.6346\n",
      "Epoch 34/100\n",
      "240/240 [==============================] - 0s 444us/step - loss: 25.3067 - val_loss: 23.4155\n",
      "Epoch 35/100\n",
      "240/240 [==============================] - 0s 422us/step - loss: 25.9530 - val_loss: 22.2973\n",
      "Epoch 36/100\n",
      "240/240 [==============================] - 0s 405us/step - loss: 25.9989 - val_loss: 23.7843\n",
      "Epoch 37/100\n",
      "240/240 [==============================] - 0s 373us/step - loss: 26.5481 - val_loss: 22.6191\n",
      "Epoch 38/100\n",
      "240/240 [==============================] - 0s 389us/step - loss: 25.5179 - val_loss: 22.3024\n",
      "Epoch 39/100\n",
      "240/240 [==============================] - 0s 413us/step - loss: 25.2488 - val_loss: 24.0604\n",
      "Epoch 40/100\n",
      "240/240 [==============================] - 0s 389us/step - loss: 25.8740 - val_loss: 30.3646\n",
      "Epoch 41/100\n",
      "240/240 [==============================] - 0s 398us/step - loss: 24.9716 - val_loss: 26.4941\n",
      "Epoch 42/100\n",
      "240/240 [==============================] - 0s 378us/step - loss: 25.7819 - val_loss: 22.4312\n",
      "Epoch 43/100\n",
      "240/240 [==============================] - 0s 380us/step - loss: 25.5949 - val_loss: 23.2365\n",
      "Epoch 44/100\n",
      "240/240 [==============================] - 0s 375us/step - loss: 27.4523 - val_loss: 27.4371\n",
      "Epoch 45/100\n",
      "240/240 [==============================] - 0s 376us/step - loss: 25.3597 - val_loss: 22.3169\n",
      "Epoch 46/100\n",
      "240/240 [==============================] - 0s 371us/step - loss: 25.9767 - val_loss: 22.1295\n",
      "Epoch 47/100\n",
      "240/240 [==============================] - 0s 367us/step - loss: 25.4210 - val_loss: 23.3022\n",
      "Epoch 48/100\n",
      "240/240 [==============================] - 0s 381us/step - loss: 26.5661 - val_loss: 24.7010\n",
      "Epoch 49/100\n",
      "240/240 [==============================] - 0s 377us/step - loss: 25.6041 - val_loss: 22.6664\n",
      "Epoch 50/100\n",
      "240/240 [==============================] - 0s 376us/step - loss: 25.3614 - val_loss: 22.4135\n",
      "Epoch 51/100\n",
      "240/240 [==============================] - 0s 382us/step - loss: 26.1362 - val_loss: 22.3668\n",
      "Epoch 52/100\n",
      "240/240 [==============================] - 0s 381us/step - loss: 25.5412 - val_loss: 22.3329\n",
      "Epoch 53/100\n",
      "240/240 [==============================] - 0s 377us/step - loss: 25.9337 - val_loss: 25.3479\n",
      "Epoch 54/100\n",
      "240/240 [==============================] - 0s 378us/step - loss: 25.3680 - val_loss: 31.8363\n",
      "Epoch 55/100\n",
      "240/240 [==============================] - 0s 375us/step - loss: 25.5870 - val_loss: 22.3212\n",
      "Epoch 56/100\n",
      "240/240 [==============================] - 0s 377us/step - loss: 25.8529 - val_loss: 22.1954\n",
      "Epoch 57/100\n",
      "240/240 [==============================] - 0s 376us/step - loss: 25.6575 - val_loss: 23.0277\n",
      "Epoch 58/100\n",
      "240/240 [==============================] - 0s 373us/step - loss: 26.0293 - val_loss: 22.0544\n",
      "Epoch 59/100\n",
      "240/240 [==============================] - 0s 375us/step - loss: 25.2026 - val_loss: 22.3400\n",
      "Epoch 60/100\n",
      "240/240 [==============================] - 0s 492us/step - loss: 25.7902 - val_loss: 23.1943\n",
      "Epoch 61/100\n",
      "240/240 [==============================] - 0s 500us/step - loss: 25.9877 - val_loss: 24.8450\n",
      "Epoch 62/100\n",
      "240/240 [==============================] - 0s 377us/step - loss: 26.0800 - val_loss: 22.3634\n",
      "Epoch 63/100\n",
      "240/240 [==============================] - 0s 370us/step - loss: 26.2933 - val_loss: 22.0646\n",
      "Epoch 64/100\n",
      "240/240 [==============================] - 0s 373us/step - loss: 25.5454 - val_loss: 23.0081\n",
      "Epoch 65/100\n",
      "240/240 [==============================] - 0s 375us/step - loss: 25.7951 - val_loss: 23.5951\n",
      "Epoch 66/100\n",
      "240/240 [==============================] - 0s 368us/step - loss: 25.5050 - val_loss: 24.1178\n",
      "Epoch 67/100\n",
      "240/240 [==============================] - 0s 372us/step - loss: 25.2405 - val_loss: 38.8868\n",
      "Epoch 68/100\n",
      "240/240 [==============================] - 0s 378us/step - loss: 25.3321 - val_loss: 38.8049\n",
      "Epoch 69/100\n",
      "240/240 [==============================] - 0s 372us/step - loss: 26.3354 - val_loss: 22.3313\n",
      "Epoch 70/100\n",
      "240/240 [==============================] - 0s 372us/step - loss: 26.0272 - val_loss: 22.6522\n",
      "Epoch 71/100\n",
      "240/240 [==============================] - 0s 373us/step - loss: 27.4286 - val_loss: 23.1573\n",
      "Epoch 72/100\n",
      "240/240 [==============================] - 0s 373us/step - loss: 24.9961 - val_loss: 28.8578\n",
      "Epoch 73/100\n",
      "240/240 [==============================] - 0s 370us/step - loss: 26.5177 - val_loss: 26.7284\n",
      "Epoch 74/100\n",
      "240/240 [==============================] - 0s 371us/step - loss: 25.1670 - val_loss: 24.7381\n",
      "Epoch 75/100\n",
      "240/240 [==============================] - 0s 365us/step - loss: 25.6892 - val_loss: 22.7689\n",
      "Epoch 76/100\n",
      "240/240 [==============================] - 0s 372us/step - loss: 25.9715 - val_loss: 26.4218\n",
      "Epoch 77/100\n",
      "240/240 [==============================] - 0s 376us/step - loss: 25.3517 - val_loss: 23.1748\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 376us/step - loss: 27.2147 - val_loss: 22.0522\n",
      "Epoch 79/100\n",
      "240/240 [==============================] - 0s 376us/step - loss: 25.1167 - val_loss: 24.7362\n",
      "Epoch 80/100\n",
      "240/240 [==============================] - 0s 370us/step - loss: 25.1169 - val_loss: 27.0094\n",
      "Epoch 81/100\n",
      "240/240 [==============================] - 0s 370us/step - loss: 25.4688 - val_loss: 28.7553\n",
      "Epoch 82/100\n",
      "240/240 [==============================] - 0s 370us/step - loss: 25.8608 - val_loss: 22.1051\n",
      "Epoch 83/100\n",
      "240/240 [==============================] - 0s 373us/step - loss: 26.0499 - val_loss: 22.2846\n",
      "Epoch 84/100\n",
      "240/240 [==============================] - 0s 378us/step - loss: 26.2262 - val_loss: 24.6334\n",
      "Epoch 85/100\n",
      "240/240 [==============================] - 0s 409us/step - loss: 25.1829 - val_loss: 23.2906\n",
      "Epoch 86/100\n",
      "240/240 [==============================] - 0s 380us/step - loss: 25.0714 - val_loss: 22.6125\n",
      "Epoch 87/100\n",
      "240/240 [==============================] - 0s 374us/step - loss: 24.9040 - val_loss: 33.3341\n",
      "Epoch 88/100\n",
      "240/240 [==============================] - 0s 365us/step - loss: 27.2876 - val_loss: 25.2751\n",
      "Epoch 89/100\n",
      "240/240 [==============================] - 0s 367us/step - loss: 25.8883 - val_loss: 25.1176\n",
      "Epoch 90/100\n",
      "240/240 [==============================] - 0s 375us/step - loss: 25.0821 - val_loss: 22.9793\n",
      "Epoch 91/100\n",
      "240/240 [==============================] - 0s 377us/step - loss: 25.9949 - val_loss: 24.6302\n",
      "Epoch 92/100\n",
      "240/240 [==============================] - 0s 369us/step - loss: 26.3939 - val_loss: 38.2827\n",
      "Epoch 93/100\n",
      "240/240 [==============================] - 0s 371us/step - loss: 26.2922 - val_loss: 23.2932\n",
      "Epoch 94/100\n",
      "240/240 [==============================] - 0s 370us/step - loss: 25.1319 - val_loss: 22.4007\n",
      "Epoch 95/100\n",
      "240/240 [==============================] - 0s 370us/step - loss: 27.7727 - val_loss: 38.3222\n",
      "Epoch 96/100\n",
      "240/240 [==============================] - 0s 377us/step - loss: 25.5240 - val_loss: 22.0933\n",
      "Epoch 97/100\n",
      "240/240 [==============================] - 0s 375us/step - loss: 24.9630 - val_loss: 22.1838\n",
      "Epoch 98/100\n",
      "240/240 [==============================] - 0s 372us/step - loss: 26.0904 - val_loss: 26.6234\n",
      "Epoch 99/100\n",
      "240/240 [==============================] - 0s 372us/step - loss: 25.6752 - val_loss: 23.2468\n",
      "Epoch 100/100\n",
      "240/240 [==============================] - 0s 367us/step - loss: 25.0984 - val_loss: 23.1937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1648dc340>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x_train,y_train, batch_size=32,validation_data=(x_test,y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d786c",
   "metadata": {},
   "source": [
    "# Predicting the results of the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d8af154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 282us/step\n",
      "[[ 23.94 431.23]\n",
      " [ 23.94 460.01]\n",
      " [ 23.94 461.14]\n",
      " ...\n",
      " [ 23.94 473.26]\n",
      " [ 23.94 438.  ]\n",
      " [ 23.94 463.28]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(x_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79aa59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11048d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872310f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf86100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
